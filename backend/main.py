# backend/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
import os


# ===========================
# 1) ENV LOAD
# ===========================
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"

load_dotenv(ENV_PATH)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise RuntimeError(
        "\nğŸš¨ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        "backend/.env íŒŒì¼ì„ ë§Œë“¤ê³  ì•„ë˜ì²˜ëŸ¼ ì…ë ¥í•˜ì„¸ìš”.\n\n"
        "OPENAI_API_KEY=sk-xxxx\n"
    )

client = OpenAI(api_key=OPENAI_API_KEY)


# ===========================
# 2) FASTAPI CONFIG
# ===========================
app = FastAPI(
    title="TAPI-AI Simulator API",
    description="ë¦¬ë”ì‹­ ì‹œë®¬ë ˆì´ì…˜ AI",
    version="1.1.0",
)

FRONTEND_ORIGINS = [
    "http://localhost:5173",
    "https://ë„¤íŠ¸ë¦¬íŒŒì´ë„ë©”ì¸.netlify.app",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=FRONTEND_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===========================
# 3) PERSONA PROFILES
# ===========================
PERSONA_PROMPTS = {
    "quiet": """
ë„ˆëŠ” 'ì¡°ìš©í•œ ì„±ì‹¤í˜• íŒ€ì›'ì´ë‹¤.
- ê°ì • í‘œí˜„ì„ ê³¼í•˜ê²Œ í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì§§ì€ ë¬¸ì¥, ê³µì†í•œ ë§íˆ¬.
- ê°ˆë“± ìƒí™©ì—ì„œ ë¨¼ì € ì–‘ë³´í•œë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
""",
    "idea": """
ë„ˆëŠ” 'ììœ ì¶”êµ¬í˜• ì•„ì´ë””ì–´ íŒ€ì›'ì´ë‹¤.
- ìƒê°ì„ ë°”ë¡œë°”ë¡œ ì–˜ê¸°í•œë‹¤.
- ì°½ì˜ì  ì‹œë„, í™•ì¥ëœ ì‚¬ê³ ë¥¼ ì„ í˜¸í•œë‹¤.
- ê°ì • í‘œí˜„ì´ í’ë¶€í•˜ë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
""",
    "social": """
ë„ˆëŠ” 'ê´€ê³„ì§€í–¥ í˜‘ë ¥í˜• íŒ€ì›'ì´ë‹¤.
- íŒ€ ë¶„ìœ„ê¸°ì— ë¯¼ê°í•˜ë‹¤.
- ë¶€ë“œëŸ¬ìš´ í‘œí˜„ì„ ì„ í˜¸í•œë‹¤.
- ìƒëŒ€ì˜ ê°ì •ì„ ë¨¼ì € ê³ ë ¤í•œë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
"""
}


# ===========================
# 3-1) MOCK ì‘ë‹µ ìƒì„±ê¸°
# ===========================
def generate_mock_reply(message: str, persona: str) -> str:
    """OpenAI ì‹¤íŒ¨ ì‹œ í˜ë¥´ì†Œë‚˜ë³„ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ"""
    m = message.strip()

    if persona == "idea":
        return (
            f"ì˜¤, \"{m}\" ì´ ë¶€ë¶„ ì§„ì§œ í¥ë¯¸ë¡œìš´ë°ìš”! "
            "ë§Œì•½ ì‹œê°„ì„ ì¡°ê¸ˆ ë” ë°›ëŠ”ë‹¤ë©´ ì™„ì „íˆ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ë„ ìˆì–´ìš”. "
            "ì§€ê¸ˆ ë– ì˜¤ë¥¸ ì•„ì´ë””ì–´ê°€ ëª‡ ê°€ì§€ ìˆëŠ”ë°, ì´ì•¼ê¸°í•´ë´ë„ ë ê¹Œìš”?"
        )

    if persona == "social":
        return (
            f"\"{m}\"ë¼ê³  ë§ì”€í•´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. "
            "í˜¹ì‹œ ì œê°€ ë„ˆë¬´ ë¶€ë‹´ì„ ë“œë¦° ë¶€ë¶„ì´ ìˆì—ˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”. "
            "ê°™ì´ ë§ì¶°ê°€ë©´ ì¢‹ê² ì–´ìš”."
        )

    # quiet ê¸°ë³¸
    return (
        f"ì•Œê² ìŠµë‹ˆë‹¤. \"{m}\" ë§ì”€ ì£¼ì‹  ë‚´ìš©ì€ ì˜ ì´í•´í–ˆìŠµë‹ˆë‹¤. "
        "ì œê°€ ë¶€ì¡±í–ˆë˜ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì²œì²œíˆ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
    )


# ===========================
# 4) Request Body
# ===========================
class ChatRequest(BaseModel):
    message: str
    persona: str = "quiet"
    simulation_id: Optional[int] = None


# ===========================
# 5) Health
# ===========================
@app.get("/health")
def health():
    return {"status": "ok"}


# ===========================
# 6) CHAT API
# ===========================
@app.post("/chat")
def chat(req: ChatRequest):
    persona_prompt = PERSONA_PROMPTS.get(req.persona, PERSONA_PROMPTS["quiet"])

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": persona_prompt},
                {"role": "user", "content": req.message},
            ],
            max_tokens=250,
            temperature=0.7,
        )
        reply = response.choices[0].message.content.strip()
        is_mock = False

    except Exception as e:
        # quota / network / key missing ë“±
        err = str(e)
        if "insufficient_quota" in err or "billing" in err:
            reply = generate_mock_reply(req.message, req.persona)
            is_mock = True
        else:
            raise HTTPException(
                status_code=500,
                detail=f"â— OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {err}"
            )

    return {
        "reply": reply,
        "persona": req.persona,
        "simulation_id": req.simulation_id,
        "mock": is_mock,
    }
