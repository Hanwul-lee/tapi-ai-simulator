# backend/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
from dotenv import load_dotenv
from pathlib import Path
import os

import google.generativeai as genai


# ===========================
# 1) ENV LOAD (Gemini)
# ===========================
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"

load_dotenv(ENV_PATH)

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise RuntimeError(
        "\nğŸš¨ GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        "Render ì½˜ì†” Environment ë˜ëŠ” backend/.env íŒŒì¼ì— ì•„ë˜ì²˜ëŸ¼ ì…ë ¥í•˜ì„¸ìš”.\n\n"
        "GEMINI_API_KEY=your-gemini-api-key\n"
    )

genai.configure(api_key=GEMINI_API_KEY)
GEMINI_MODEL_NAME = "gemini-1.5-pro"


# ===========================
# 2) FASTAPI CONFIG
# ===========================
app = FastAPI(
    title="TAPI-AI Simulator API",
    description="ë¦¬ë”ì‹­ ì‹œë®¬ë ˆì´ì…˜ AI (Gemini)",
    version="1.2.0",
)

FRONTEND_ORIGINS = [
    "http://localhost:5173",
    "https://tapiaisimulator.netlify.app",  # Netlify ì£¼ì†Œë¡œ ìˆ˜ì •
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=FRONTEND_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===========================
# 3) PERSONA PROFILES
# ===========================
PERSONA_PROMPTS = {
    "quiet": """
ë„ˆëŠ” 'ì¡°ìš©í•œ ì„±ì‹¤í˜• íŒ€ì›'ì´ë‹¤.
- ê°ì • í‘œí˜„ì„ ê³¼í•˜ê²Œ í•˜ì§€ ì•ŠëŠ”ë‹¤.
- ì§§ì€ ë¬¸ì¥, ê³µì†í•œ ë§íˆ¬.
- ê°ˆë“± ìƒí™©ì—ì„œ ë¨¼ì € ì–‘ë³´í•œë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
""",
    "idea": """
ë„ˆëŠ” 'ììœ ì¶”êµ¬í˜• ì•„ì´ë””ì–´ íŒ€ì›'ì´ë‹¤.
- ìƒê°ì„ ë°”ë¡œë°”ë¡œ ì–˜ê¸°í•œë‹¤.
- ì°½ì˜ì  ì‹œë„, í™•ì¥ëœ ì‚¬ê³ ë¥¼ ì„ í˜¸í•œë‹¤.
- ê°ì • í‘œí˜„ì´ í’ë¶€í•˜ë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
""",
    "social": """
ë„ˆëŠ” 'ê´€ê³„ì§€í–¥ í˜‘ë ¥í˜• íŒ€ì›'ì´ë‹¤.
- íŒ€ ë¶„ìœ„ê¸°ì— ë¯¼ê°í•˜ë‹¤.
- ë¶€ë“œëŸ¬ìš´ í‘œí˜„ì„ ì„ í˜¸í•œë‹¤.
- ìƒëŒ€ì˜ ê°ì •ì„ ë¨¼ì € ê³ ë ¤í•œë‹¤.
AI / í”„ë¡¬í”„íŠ¸ / ëª¨ë¸ ê°™ì€ ë‹¨ì–´ë¥¼ ì ˆëŒ€ ë§í•˜ì§€ ì•ŠëŠ”ë‹¤.
""",
}


# ===========================
# 3-1) MOCK ì‘ë‹µ ìƒì„±ê¸°
# ===========================
def generate_mock_reply(message: str, persona: str) -> str:
    """Gemini í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í˜ë¥´ì†Œë‚˜ë³„ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ"""
    m = message.strip()

    if persona == "idea":
        return (
            f"ì˜¤, \"{m}\" ì´ ë¶€ë¶„ ì§„ì§œ í¥ë¯¸ë¡œìš´ë°ìš”! "
            "ë§Œì•½ ì‹œê°„ì„ ì¡°ê¸ˆ ë” ë°›ëŠ”ë‹¤ë©´ ì™„ì „íˆ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ë„ ìˆì–´ìš”. "
            "ì§€ê¸ˆ ë– ì˜¤ë¥¸ ì•„ì´ë””ì–´ê°€ ëª‡ ê°€ì§€ ìˆëŠ”ë°, ì´ì•¼ê¸°í•´ë´ë„ ë ê¹Œìš”?"
        )

    if persona == "social":
        return (
            f"\"{m}\"ë¼ê³  ë§ì”€í•´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. "
            "í˜¹ì‹œ ì œê°€ ë„ˆë¬´ ë¶€ë‹´ì„ ë“œë¦° ë¶€ë¶„ì´ ìˆì—ˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”. "
            "ê°™ì´ ë§ì¶°ê°€ë©´ ì¢‹ê² ì–´ìš”."
        )

    # quiet ê¸°ë³¸
    return (
        f"ì•Œê² ìŠµë‹ˆë‹¤. \"{m}\" ë§ì”€ ì£¼ì‹  ë‚´ìš©ì€ ì˜ ì´í•´í–ˆìŠµë‹ˆë‹¤. "
        "ì œê°€ ë¶€ì¡±í–ˆë˜ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì²œì²œíˆ ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤."
    )


# ===========================
# 4) Request Body
# ===========================
class ChatRequest(BaseModel):
    message: str
    persona: str = "quiet"
    simulation_id: Optional[int] = None


# ===========================
# 5) Health
# ===========================
@app.get("/health")
def health():
    return {"status": "ok"}


# ===========================
# 6) CHAT API (Gemini)
# ===========================
@app.post("/chat")
def chat(req: ChatRequest):
    persona_prompt = PERSONA_PROMPTS.get(req.persona, PERSONA_PROMPTS["quiet"])

    # Geminiì— ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    full_prompt = f"""
ë‹¤ìŒì€ íŒ€ì¥ê³¼ íŒ€ì› ì‚¬ì´ì˜ 1:1 ë©´ë‹´ì´ë‹¤.

[íŒ€ì› ì„¤ì •]
{persona_prompt}

[ë¦¬ë”ì˜ ë°œí™”]
{req.message}

ìœ„ ìƒí™©ì—ì„œ, íŒ€ì›ì˜ ì…ì¥ì—ì„œë§Œ ëŒ€ë‹µí•˜ë¼.
- ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ êµ¬ì–´ì²´ë¡œ 3~5ë¬¸ì¥ ì •ë„ë¡œ ë§í•œë‹¤.
- ì½”ì¹˜ë‚˜ ì„¤ëª…ìê°€ ì•„ë‹ˆë¼, ì‹¤ì œ íŒ€ì›ì´ ë©”ì‹ ì €ì— ë‹µí•˜ë“¯ì´ ë§í•œë‹¤.
- AI, í”„ë¡¬í”„íŠ¸, ëª¨ë¸, Gemini ê°™ì€ ë‹¨ì–´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ì•ŠëŠ”ë‹¤.
"""

    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        response = model.generate_content(full_prompt)
        reply = (response.text or "").strip()
        is_mock = False

        if not reply:
            # í˜¹ì‹œ ë¹ˆ ì‘ë‹µì´ë©´ mock ì‚¬ìš©
            reply = generate_mock_reply(req.message, req.persona)
            is_mock = True

    except Exception as e:
        # ì¿¼í„°/ë„¤íŠ¸ì›Œí¬ ë“± ì˜¤ë¥˜ â†’ mock ì‘ë‹µ
        err = str(e)
        print("Gemini error:", err)
        reply = generate_mock_reply(req.message, req.persona)
        is_mock = True

    return {
        "reply": reply,
        "persona": req.persona,
        "simulation_id": req.simulation_id,
        "mock": is_mock,
    }
